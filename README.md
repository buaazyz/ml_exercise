
# 运行顺序
先运行 train.py
再运行 eavl.py 

### 请自行添加数据集，此为三分类的数据集，数据的处理在preprocess.py里面
---

# 实验报告
## 一、数据预处理
1）缺失值的处理
2）多余信息处理
3）文字数据转为标量
4）在数据总体的describe中发现缺少了若干列，经检查发现是由于这些列的数据中数字的后面加了"?"，导致pandas读入时将该列作为object存储在处理？的同时发现了还有一些数据存储为None，为了后续方便处理，将None改成了NaN。通过查看数据可以看出？可能是在原数据集中小数点没有正确输入导致的所以通过将？代替成. ，并通过正则表达式取出第一个有效的小数。
5）最后考虑到数据集绝大部分都是连续数字，所以应对数据进行归一化处理，这里为了避免异常值影响，所以采用的是zscore的归一化
6)尝试了通过PCA和TSNE降维到2维和3维，并绘制了2D和3D的散点图，但是直观上觉得三种类型的分别很不明显
7）降维主要采取了两种方法，第一步是通过检查各特征的方差，删去方差小于0.001的特征；第二步是通过random forests的树模型的特征提取，再次筛选掉重要性小于0.001的特征

---

## 二、模型构建
1）该训练集有个很大的问题就是，类别的数据极度不平衡，首先分层采样了10%的样本数据作为最后的测试集，如下表
类别	   类别1	  类别2	 类别3
训练集	59	  1856	  228
测试集	7	  206	   25
2）对于如何处理不平衡的数据，我采取的方法是，以200数据样集作为基数，对疑似圆锥角膜采取欠抽样的方法，同时，对于只有59条数据的圆锥角膜类型，我采用的是SMOTE算法的过采样方法，将其增量到228条
3）方案一是采用基于SVM的bagging
在采用SVM时，由于sklearn自带的BaggingClassifier不支持进行重新抽样的bagging，所以，只好自行实现bagging，但是由于SVM的w系数只有在采用线性核的情况下才能取出，所以在此次实验中并没有采用高斯核
4）方案二是采用的boost的方法，考虑到这种多分类的问题，更适合树模型的机器学习模型，所以训练两个模型，一个是xgboost模型，一个是GBDT模型，由于树模型不需要对训练集进行标准化，所以，取的是仅删去了特征方差小于0.001的数据集。
5）训练调参，关于SVM的超参数，需要的是对C和gamma进行调试，采用网格搜索穷举法，通过比较C取0.1，gamma取自适应后，训练结果更好。关于xgboost和GBDT的超参数，n_estimators，learning_rate，max_depth，本次实验只对弱分类器的数量进行调试，其他几个参数采用了默认值。

---

## 三、模型评估与不足
1）SVM的bagging效果不甚理想，模型的正确率只在60%左右，考虑过采用rbf核，但是由于sklearn的SVM在rbf核下不能取得w值，所以，后续打算自己实现SVM并训练rbf核的bagging，其中SV的基本模型已经在model的目录下实现，但模型的关于冷热数据和cache的功能还未实现，所以由于本实验的时间限制，暂时只能先采用sklearn的SVM。
2）xgboost和GBDT的预测正确率高达100%，让我觉得模型会不会是过拟合了，由于没有对训练集进行欠抽样或者过抽样的操作，只是简单的进行数据清洗后就放入xgboost和GBDT进行训练而且结果还是100%的准确率，我也不知道该从哪些方面入手进行关于过拟合方面的调整。下图是xgboost的评估结果。
